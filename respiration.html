<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python Monitor Code</title>
    <style>
        body { font-family: monospace; background-color: #f5f5f5; padding: 20px; }
        pre { background-color: #272822; color: #f8f8f2; padding: 20px; border-radius: 5px; overflow-x: auto; }
    </style>
</head>
<body>
    <pre><code>import cv2
import numpy as np
import mediapipe as mp
from collections import deque
from scipy.signal import butter, filtfilt, welch, find_peaks
import time

# === PARAMETERS ===
DURATION_SEC = 30
FPS = 30
BUFFER_SIZE = 900  # 30 seconds at 30 FPS
HR_BAND = (1.0, 2.0)  # 60â€“120 bpm
RESP_MIN_DIST = 0.5  # seconds
last_valid_hr = None


# === BANDPASS FILTER ===
def bandpass(data, fs, low, high, order=4):
    nyq = 0.5 * fs
    b, a = butter(order, [low / nyq, high / nyq], btype='band')
    return filtfilt(b, a, data)

# === Mediapipe Setup ===
mp_pose_module = mp.solutions.pose
pose = mp_pose_module.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)

mp_face_module = mp.solutions.face_mesh
face_mesh = mp_face_module.FaceMesh(min_detection_confidence=0.5)

# === Video and Buffers ===
cap = cv2.VideoCapture(0)
resp_buffer = deque(maxlen=BUFFER_SIZE)
ppg_buffer = deque(maxlen=BUFFER_SIZE)
time_buffer = deque(maxlen=BUFFER_SIZE)
start_time = cv2.getTickCount() / cv2.getTickFrequency()

while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    h, w = frame.shape[:2]
    t = (cv2.getTickCount() / cv2.getTickFrequency()) - start_time
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # === Pose (for respiration) ===
    p = pose.process(rgb)
    if p.pose_landmarks:
        lm = p.pose_landmarks.landmark
        l_sh = lm[mp_pose_module.PoseLandmark.LEFT_SHOULDER]
        r_sh = lm[mp_pose_module.PoseLandmark.RIGHT_SHOULDER]
        chest_y = ((l_sh.y + r_sh.y) / 2) * h
        resp_buffer.append(chest_y)
        time_buffer.append(t)

    # === Face (for heart rate) ===
    f = face_mesh.process(rgb)
    if f.multi_face_landmarks:
        pts = f.multi_face_landmarks[0].landmark

        # Forehead region between eyes
        x_coords = [pts[10].x, pts[338].x, pts[297].x, pts[332].x]
        y_coords = [pts[10].y, pts[338].y, pts[297].y, pts[332].y]

        x_min = int(min(x_coords) * w)
        x_max = int(max(x_coords) * w)
        y_min = int(min(y_coords) * h) - 20
        y_max = y_min + 30

        x_min = max(0, x_min)
        x_max = min(w, x_max)
        y_min = max(0, y_min)
        y_max = min(h, y_max)

        roi = frame[y_min:y_max, x_min:x_max]
        if roi.size:
            green_avg = np.mean(roi[:, :, 1])
            ppg_buffer.append(green_avg)

    # === Graph Visualization ===
    graph_h = 300
    graph = np.zeros((graph_h, BUFFER_SIZE, 3), dtype=np.uint8)

    if len(resp_buffer) > 1:
        arr = np.array(resp_buffer)
        norm = (arr - arr.min()) / (arr.max() - arr.min() + 1e-6)
        ys = ((1 - norm) * (graph_h // 2 - 1)).astype(int)
        for i in range(1, len(ys)):
            cv2.line(graph, (i-1, ys[i-1]), (i, ys[i]), (0, 255, 0), 1)

    if len(ppg_buffer) > 1:
        arr = np.array(ppg_buffer)
        norm = (arr - arr.min()) / (arr.max() - arr.min() + 1e-6)
        ys = ((1 - norm) * (graph_h - 1 - graph_h // 2)).astype(int) + graph_h // 2
        for i in range(1, len(ys)):
            cv2.line(graph, (i-1, ys[i-1]), (i, ys[i]), (255, 0, 0), 1)

    cam_resized = cv2.resize(frame, (BUFFER_SIZE, BUFFER_SIZE))
    monitor = cv2.vconcat([cam_resized, graph])

    # === Respiration Rate ===
    resp_rate = None
    if len(resp_buffer) > FPS * 5:
        x = np.array(resp_buffer)
        detrended = x - np.mean(x)
        peaks, _ = find_peaks(detrended, distance=RESP_MIN_DIST * FPS)
        duration = time_buffer[-1] - time_buffer[0]
        if duration > 0:
            resp_rate = len(peaks) / (duration / 60)
            # Visual Cue for Respiration Rate
            if resp_rate > 18:  # Fast breathing
                cv2.putText(monitor, f"RR: {resp_rate:.1f} rpm", (10, BUFFER_SIZE - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:  # Normal
                cv2.putText(monitor, f"RR: {resp_rate:.1f} rpm", (10, BUFFER_SIZE - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

    # === Heart Rate ===
    heart_rate = None
    if len(ppg_buffer) > FPS * 5:
        y = np.array(ppg_buffer)
        y_d = y - np.mean(y)
        y_f = bandpass(y_d, FPS, HR_BAND[0], HR_BAND[1])
        freqs, psd = welch(y_f, fs=FPS, nperseg=min(256, len(y_f)))
        mask = (freqs >= HR_BAND[0]) & (freqs <= HR_BAND[1])
        if np.any(mask):
            peak_freq = freqs[mask][np.argmax(psd[mask])]
            heart_rate = peak_freq * 60

            # Signal confidence check
            signal_power = np.max(psd[mask])
            noise_floor = np.median(psd[mask])
            if signal_power / noise_floor > 3:
                # Visual Cue for Heart Rate
                if heart_rate > 100:  # High HR
                    cv2.putText(monitor, f"HR: {heart_rate:.0f} bpm", (200, BUFFER_SIZE - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    last_valid_hr = heart_rate
                else:  # Normal HR
                    cv2.putText(monitor, f"HR: {heart_rate:.0f} bpm", (200, BUFFER_SIZE - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                    last_valid_hr = heart_rate
            else:
                heart_rate = None

    # === Overlay Text ===
    cv2.putText(monitor, "Camera Feed", (10, 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
    cv2.putText(monitor, "Respiration (green)", (10, BUFFER_SIZE + 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
    cv2.putText(monitor, "PPG / Heart (blue)", (10, BUFFER_SIZE + graph_h // 2 + 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1)

    # === Show Monitor ===
    cv2.imshow("Monitor", monitor)
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q') or t > DURATION_SEC:
        break
heart_rate = str(heart_rate) if heart_rate is not None else None
last_valid_hr = str(last_valid_hr) if last_valid_hr is not None else None
if heart_rate is None:
    print("Heart Rate: "+ last_valid_hr + " bpm")
else:
    print("Heart Rate:", heart_rate, "bpm")
print("Respiration Rate:", resp_rate, "rpm")
cap.release()
cv2.destroyAllWindows()</code></pre>
</body>
</html>
